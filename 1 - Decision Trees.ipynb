{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de decisión\n",
    "\n",
    "es un árbol de clasificación binaria (como los árboles de Huffman) construído de manera top-down.  \n",
    "Para un conjunto de observaciones de entrenamiento se va partiendo el dataset en dos recursivamente hasta llegar a una condición de conjunto mínimo. Explicación en el pizarrón.\n",
    "\n",
    "https://www.youtube.com/watch?v=7VeUPuFGJHk\n",
    "\n",
    "https://www.youtube.com/watch?v=DCZ3tsQIoGU\n",
    "\n",
    "## Ganancia de Información\n",
    "\n",
    "$$ IG=H(S)-\\sum_v \\frac{|S_v|}{|S|} H(S_v) $$\n",
    "\n",
    "## Gini impurity\n",
    "\n",
    "Utilizado por el algoritmo de ACR (Árboles de Clasificación y Regresión), la impureza de Gini es una medida de cuán a menudo un elemento elegido aleatoriamente del conjunto sería etiquetado incorrectamente si fue etiquetado de manera aleatoria de acuerdo a la distribución de las etiquetas en el subconjunto. La impureza de Gini se puede calcular sumando la probabilidad de cada elemento siendo elegido multiplicado por la probabilidad de un error en la categorización de ese elemento. Alcanza su mínimo (cero) cuando todos los casos del nodo corresponden a una sola categoría de destino.\n",
    "\n",
    "Para calcular la impureza de Gini de un conjunto de elementos, supongamos i toma valores en $\\{1, 2, ..., m\\}$, y sea $f_i$ la fracción de artículos etiquetados con valor $i$ en el conjunto.\n",
    "\n",
    "$$I_{G}(f) = \\sum_{i=1}^{m} f_i (1-f_i) = \\sum_{i=1}^{m} (f_i - {f_i}^2) = \\sum_{i=1}^m f_i - \\sum_{i=1}^{m} {f_i}^2 = 1 - \\sum^{m}_{i=1} {f_i}^{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desventajas\n",
    "\n",
    "* NP completo\n",
    "* Se pueden crear árboles muy complejos que no generalizan bien ya que se toman en cuenta muchos casos particulares. Se soluciona con pruning. No implementado en sklearn.\n",
    "\n",
    "\n",
    "## Ventajas\n",
    "* Interpretabilidad\n",
    "* Poca preparación de datos (no hace falta normalización, por ej)\n",
    "* La predicción es muy rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "  \n",
    "# Function importing Dataset \n",
    "def importdata(): \n",
    "    balance_data = pd.read_csv( \n",
    "'https://archive.ics.uci.edu/ml/machine-learning-'+\n",
    "'databases/balance-scale/balance-scale.data', \n",
    "    sep= ',', header = None) \n",
    "      \n",
    "    # Printing the dataswet shape \n",
    "    print (\"Dataset Lenght: \", len(balance_data)) \n",
    "    print (\"Dataset Shape: \", balance_data.shape) \n",
    "      \n",
    "    # Printing the dataset obseravtions \n",
    "    print (\"Dataset: \",balance_data.head()) \n",
    "    return balance_data \n",
    "  \n",
    "# Function to split the dataset \n",
    "def splitdataset(balance_data): \n",
    "  \n",
    "    # Seperating the target variable \n",
    "    X = balance_data.values[:, 1:5] \n",
    "    Y = balance_data.values[:, 0] \n",
    "  \n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, Y, test_size = 0.3, random_state = 100) \n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test \n",
    "      \n",
    "# Function to perform training with giniIndex. \n",
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=3, min_samples_leaf=5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini \n",
    "      \n",
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", random_state = 100, \n",
    "            max_depth = 3, min_samples_leaf = 5) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy\n",
    "\n",
    "# Function to make predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred \n",
    "      \n",
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy : \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "      \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Lenght:  625\n",
      "Dataset Shape:  (625, 5)\n",
      "Dataset:     0  1  2  3  4\n",
      "0  B  1  1  1  1\n",
      "1  R  1  1  1  2\n",
      "2  R  1  1  1  3\n",
      "3  R  1  1  1  4\n",
      "4  R  1  1  1  5\n",
      "Results Using Gini Index:\n",
      "Predicted values:\n",
      "['R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'R'\n",
      " 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R'\n",
      " 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R']\n",
      "Confusion Matrix:  [[ 0  6  7]\n",
      " [ 0 67 18]\n",
      " [ 0 19 71]]\n",
      "Accuracy :  73.40425531914893\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        13\n",
      "           L       0.73      0.79      0.76        85\n",
      "           R       0.74      0.79      0.76        90\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       188\n",
      "   macro avg       0.49      0.53      0.51       188\n",
      "weighted avg       0.68      0.73      0.71       188\n",
      "\n",
      "Results Using Entropy:\n",
      "Predicted values:\n",
      "['R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R']\n",
      "Confusion Matrix:  [[ 0  6  7]\n",
      " [ 0 63 22]\n",
      " [ 0 20 70]]\n",
      "Accuracy :  70.74468085106383\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           B       0.00      0.00      0.00        13\n",
      "           L       0.71      0.74      0.72        85\n",
      "           R       0.71      0.78      0.74        90\n",
      "\n",
      "   micro avg       0.71      0.71      0.71       188\n",
      "   macro avg       0.47      0.51      0.49       188\n",
      "weighted avg       0.66      0.71      0.68       188\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cselmo/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/cselmo/.conda/envs/doctorado-gpu/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "data = importdata() \n",
    "X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
    "clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "\n",
    "# Operational Phase \n",
    "print(\"Results Using Gini Index:\") \n",
    "\n",
    "# Prediction using gini \n",
    "y_pred_gini = prediction(X_test, clf_gini) \n",
    "cal_accuracy(y_test, y_pred_gini) \n",
    "\n",
    "print(\"Results Using Entropy:\") \n",
    "# Prediction using entropy \n",
    "y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "cal_accuracy(y_test, y_pred_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
